"""AI Safety Scoring Model."""
import numpy as np
from typing import List, Dict, Tuple, Optional
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
import joblib
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent.parent.parent))

from config.config import settings
from api.schemas.delivery import Coordinate
from api.services.crime_data import CrimeDataService
from loguru import logger
import json
from geopy.distance import distance



class SafetyScorer:
    """AI-powered safety scoring for routes."""
    
    def __init__(self, crime_service: Optional[CrimeDataService] = None):
        self.model = None
        self.scaler = StandardScaler()
        self.weights = settings.SAFETY_WEIGHTS
        self.crime_service = crime_service or CrimeDataService()
        self.police_stations = self._load_police_stations()
        self.hospitals = self._load_hospitals()
        
        # Merge with DB safe zones
        db_safe_zones = self._load_db_safe_zones()
        if db_safe_zones:
            # Add police stations from DB to the list
            db_police = [z for z in db_safe_zones if z['type'] == 'police_station']
            # Avoid duplicates by name
            existing_names = set(s['name'] for s in self.police_stations)
            for p in db_police:
                if p['name'] not in existing_names:
                    self.police_stations.append(p)
            
            # Add other safe zones (24hr shops, etc) to a general list for scoring
            self.other_safe_zones = [z for z in db_safe_zones if z['type'] != 'police_station']
            
        self._initialize_model()

    def _load_police_stations(self) -> List[Dict]:
        """Load police stations from JSON file."""
        try:
            # Try absolute path first, then relative to this file
            base_dir = Path(__file__).parent.parent.parent
            data_path = base_dir / "data" / "police_stations.json"
            if data_path.exists():
                with open(data_path, 'r') as f:
                    return json.load(f)
        except Exception as e:
            logger.error(f"Error loading police stations: {e}")
        return []

    def _load_db_safe_zones(self) -> List[Dict]:
        """Load safe zones from the database."""
        try:
            from database.database import SessionLocal
            from database.models import SafeZone
            
            db = SessionLocal()
            zones = db.query(SafeZone).all()
            db_zones = []
            for zone in zones:
                loc = zone.location
                db_zones.append({
                    "name": zone.name,
                    "latitude": loc.get('latitude', loc.get('lat')),
                    "longitude": loc.get('longitude', loc.get('lng')),
                    "type": zone.zone_type,
                    "safety_score": zone.safety_score
                })
            db.close()
            if db_zones:
                logger.info(f"Loaded {len(db_zones)} safe zones from database")
            return db_zones
        except Exception as e:
            logger.warning(f"Could not load safe zones from DB: {e}")
        return []

    def _load_hospitals(self) -> List[Dict]:
        """Load hospitals from JSON file."""
        try:
            base_dir = Path(__file__).parent.parent.parent
            data_path = base_dir / "data" / "hospitals.json"
            if data_path.exists():
                with open(data_path, 'r') as f:
                    return json.load(f)
        except Exception as e:
            logger.error(f"Error loading hospitals: {e}")
        return []

    
    def _initialize_model(self):
        """Initialize or load the safety scoring model."""
        model_path = settings.SAFETY_MODEL_PATH
        model_dir = Path(model_path).parent
        
        # Create directory if it doesn't exist
        model_dir.mkdir(parents=True, exist_ok=True)
        
        # Try to load existing model
        if Path(model_path).exists() and Path(settings.SAFETY_SCALER_PATH).exists():
            try:
                self.model = joblib.load(model_path)
                self.scaler = joblib.load(settings.SAFETY_SCALER_PATH)
                
                # Check feature count
                if hasattr(self.model, "n_features_in_"):
                    self.feature_count = self.model.n_features_in_
                    logger.info(f"Loaded existing safety scoring model with {self.feature_count} features")
                else:
                    self.feature_count = 8
                    logger.info("Loaded models without explicit feature count attribute, assuming 8")
                    
            except Exception as e:
                logger.warning(f"Could not load model or scaler: {e}, creating new one")
                self._train_initial_model()
        else:
            logger.info("Model or scaler file missing, starting initial training")
            self._train_initial_model()
    
    def _train_initial_model(self):
        """Train initial model with enhanced data including real crime statistics."""
        # Generate training data based on real crime statistics and heuristics
        n_samples = 2000
        np.random.seed(42)
        
        # Features: [crime_rate, lighting_score, patrol_density, traffic_density, hour_of_day, police_proximity, hospital_proximity]
        X = []
        y = []
        
        # 1. Use real district centers as key training points
        districts = self.crime_service.crime_data
        for district, data in districts.items():
            coords = data["coordinates"]
            # Create a few samples around each district center
            for _ in range(20):
                # Add some jitter to coordinates
                jitter_lat = coords[0] + np.random.uniform(-0.1, 0.1)
                jitter_lng = coords[1] + np.random.uniform(-0.1, 0.1)
                
                # Get real crime score for this jittered location
                crime_score = self.crime_service.get_crime_score(Coordinate(latitude=jitter_lat, longitude=jitter_lng))
                
                # Generate other features synthetically for now
                hour = np.random.randint(0, 24)
                lighting = 80 if 6 <= hour <= 18 else np.random.uniform(20, 60)
                traffic = np.random.uniform(10, 90)
                patrol = np.random.uniform(10, 80)
                
                # Proximity to police/hospitals
                police_prox = self._calculate_proximity(Coordinate(latitude=jitter_lat, longitude=jitter_lng), self.police_stations)
                hosp_prox = self._calculate_proximity(Coordinate(latitude=jitter_lat, longitude=jitter_lng), self.hospitals)
                
                weather_hazard = 0.0
                features = [crime_score, lighting, patrol, traffic, hour, police_prox, hosp_prox, weather_hazard]
                X.append(features)
                
                # Target safety score (heuristic for initial training)
                # Lower crime, higher lighting/patrol/proximity = higher safety
                target = (
                    (100 - crime_score) * 0.4 +
                    lighting * 0.2 +
                    patrol * 0.15 +
                    (100 - traffic * 0.2) * 0.1 + # Traffic has small negative impact on safety
                    police_prox * 0.1 +
                    hosp_prox * 0.05
                )
                y.append(target)
        
        # 2. Add some purely random samples to cover other areas
        for _ in range(n_samples - len(X)):
            # Random coordinates in Tamil Nadu range
            lat = np.random.uniform(8.0, 13.5)
            lng = np.random.uniform(76.2, 80.3)
            
            crime_score = self.crime_service.get_crime_score(Coordinate(latitude=lat, longitude=lng))
            hour = np.random.randint(0, 24)
            lighting = np.random.uniform(20, 90)
            traffic = np.random.uniform(0, 100)
            patrol = np.random.uniform(0, 100)
            police_prox = np.random.uniform(0, 100)
            hosp_prox = np.random.uniform(0, 100)
            weather_hazard = np.random.uniform(0, 5) # Slight random weather hazard
            features = [crime_score, lighting, patrol, traffic, hour, police_prox, hosp_prox, weather_hazard]
            X.append(features)
            
            target = (
                (100 - crime_score) * 0.4 +
                lighting * 0.2 +
                patrol * 0.15 +
                (100 - traffic * 0.2) * 0.1 +
                police_prox * 0.1 +
                hosp_prox * 0.05 -
                weather_hazard * 2.0
            )
            y.append(target)
        
        X = np.array(X)
        y = np.array(y)
        
        # Scale features
        X_scaled = self.scaler.fit_transform(X)
        
        # Train model
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.model.fit(X_scaled, y)
        
        # Save model and scaler
        self._save_model()
        logger.info(f"Trained and saved new safety scoring model with {len(X)} samples using Real Crime Data")

    def _save_model(self):
        """Save calibrated model and scaler to disk."""
        try:
            model_path = settings.SAFETY_MODEL_PATH
            Path(model_path).parent.mkdir(parents=True, exist_ok=True)
            joblib.dump(self.model, model_path)
            joblib.dump(self.scaler, settings.SAFETY_SCALER_PATH)
            logger.info("Model and scaler saved successfully")
        except Exception as e:
            logger.error(f"Failed to save model: {e}")

    def _calculate_proximity(self, coord: Coordinate, points: List[Dict]) -> float:
        """Calculate proximity score (0-100) to nearest points."""
        if not points:
            return 30.0 # Default mediocre score if no data
            
        min_dist = float('inf')
        for p in points:
            loc = p.get('location', p.get('coordinates', {}))
            if not loc: continue
            
            p_lat = loc.get('lat', loc.get('latitude'))
            p_lng = loc.get('lng', loc.get('longitude'))
            
            if p_lat is None or p_lng is None: continue
            
            dist = distance((coord.latitude, coord.longitude), (p_lat, p_lng)).km
            min_dist = min(min_dist, dist)
            
        # Score: 100 at 0km, 0 at 10km+
        score = max(0, 100 - (min_dist * 10))
        return score
    
    def _get_location_features(
        self,
        coord: Coordinate,
        time_of_day: str = "day",
        weather_data: Optional[Dict] = None,
        delivery_info: Optional[Dict] = None
    ) -> np.ndarray:
        """Extract features for a location using real crime data."""
        # Get real crime data from Tamil Nadu crime dataset
        crime_score = self.crime_service.get_crime_score(coord)
        crime_data = self.crime_service.get_crime_data_for_location(coord)
        
        # Convert crime score to crime rate (0-10 scale)
        crime_rate = crime_score / 10.0
        
        # Lighting score (varies by location and time)
        hour_map = {"day": 12, "evening": 18, "night": 22}
        hour = hour_map.get(time_of_day, 12)
        
        # Adjust lighting based on time of day
        if hour < 6 or hour > 20:
            lighting_score = 30 + np.random.rand() * 20  # Low at night
        elif hour < 8 or hour > 18:
            lighting_score = 50 + np.random.rand() * 30  # Medium at dawn/dusk
        else:
            lighting_score = 70 + np.random.rand() * 30  # High during day
        
        # Patrol density (higher in high-crime areas)
        if crime_score > 50:
            patrol_density = 60 + np.random.rand() * 30  # More patrols in high-crime areas
        else:
            patrol_density = 40 + np.random.rand() * 40
        
        # Traffic density (mock for now, could use real traffic data)
        traffic_density = 30 + np.random.rand() * 50
        
        # Weather hazard impact (if provided)
        weather_hazard = 0
        if weather_data:
            weather_hazard = weather_data.get("hazard_score", 0) / 10.0  # Scale to 0-10
            
        # Police Proximity
        police_proximity = self._calculate_police_proximity(coord)

        # Hospital Proximity
        hospital_proximity = self._calculate_hospital_proximity(coord)
        
        # If we need 12 features for the new RF model
        if hasattr(self, 'feature_count') and self.feature_count == 12:
            is_night = 1 if (hour >= 20 or hour <= 6) else 0
            is_peak = 1 if (hour >= 22 or hour <= 4) else 0
            
            return np.array([
                crime_rate * 2,          # crime_density (approx)
                crime_rate,              # crime_severity (approx)
                10 - (police_proximity / 10), # dist to safe zone
                2 if police_proximity > 70 else 0, # safe zones nearby
                4.0,                     # avg_feedback_rating
                80.0,                    # pct_felt_safe
                lighting_score,          # pct_adequate_lighting
                is_night,                # is_night
                is_peak,                 # is_peak_time
                0.8,                     # area_urbanization
                delivery_info.get('distance', 5) if delivery_info else 5,
                delivery_info.get('duration', 15) if delivery_info else 15
            ])

        return np.array([
            crime_rate,
            lighting_score,
            patrol_density,
            traffic_density,
            hour,
            police_proximity,  # Feature 5 (0-100)
            hospital_proximity, # Feature 6 (0-100)
            weather_hazard    # Extra feature, not in main model X
        ])

    def _calculate_hospital_proximity(self, coord: Coordinate) -> float:
        """Calculate proximity score to nearest 24/7 hospital (0-100)."""
        if not self.hospitals:
            return 50.0 # Default if no data
            
        min_dist_km = float('inf')
        
        for hospital in self.hospitals:
            try:
                dist = distance(
                    (coord.latitude, coord.longitude),
                    (hospital['latitude'], hospital['longitude'])
                ).km
                if dist < min_dist_km:
                    min_dist_km = dist
            except Exception:
                continue
                
        # Proximity score: 100 if < 500m, decays to 0 at 10km
        if min_dist_km == float('inf'):
            return 0.0
            
        score = 100 * np.exp(-0.4 * min_dist_km) # Slightly slower decay than police
        return min(100.0, max(0.0, score))

    def _calculate_police_proximity(self, coord: Coordinate) -> float:
        """Calculate proximity score to nearest police station or safe zone (0-100)."""
        all_safe_points = list(self.police_stations)
        if hasattr(self, 'other_safe_zones'):
            all_safe_points.extend(self.other_safe_zones)
            
        if not all_safe_points:
            return 50.0 # Default if no data
            
        min_dist_km = float('inf')
        
        for station in all_safe_points:
            try:
                # Handle both JSON style and DB style coordinate keys
                p_lat = station.get('latitude', station.get('lat'))
                p_lng = station.get('longitude', station.get('lng'))
                
                if p_lat is None or p_lng is None:
                    # Check location dict style
                    loc = station.get('location', {})
                    p_lat = loc.get('lat', loc.get('latitude'))
                    p_lng = loc.get('lng', loc.get('longitude'))
                
                if p_lat is None or p_lng is None: continue

                dist = distance(
                    (coord.latitude, coord.longitude),
                    (p_lat, p_lng)
                ).km
                if dist < min_dist_km:
                    min_dist_km = dist
            except Exception:
                continue
                
        # Proximity score: 100 if < 500m, decays to 0 at 10km
        if min_dist_km == float('inf'):
            return 0.0
            
        score = 100 * np.exp(-0.5 * min_dist_km)
        return min(100.0, max(0.0, score))
    
    def score_location(
        self,
        coord: Coordinate,
        time_of_day: str = "day",
        rider_info: Optional[Dict] = None,
        weather_data: Optional[Dict] = None
    ) -> Tuple[float, List[Dict]]:
        """Score a single location for safety.
        
        Returns:
            Tuple of (overall_score, factors_list)
        """
        features = self._get_location_features(coord, time_of_day, weather_data)
        
        # Adjust feature set based on what model expects
        feat_count = getattr(self, 'feature_count', 7)
        features_for_model = features[:feat_count].reshape(1, -1)
        
        # Scaling
        if self.scaler:
            features_for_model = self.scaler.transform(features_for_model)
        
        # Get model prediction
        base_score = self.model.predict(features_for_model)[0]
        # Apply gender-specific adjustments if needed
        if rider_info and rider_info.get("gender") == "female":
            # Determine indices based on feature count
            feat_cnt = getattr(self, "feature_count", 7)
            if feat_cnt == 12:
                # 12-feature model: index 6 is lighting, index 1 is crime_severity
                if features[6] < 50:  # Low lighting
                    base_score -= 10
                if features[1] > 5:   # High crime (0-10 scale)
                    base_score -= 10
            else:
                # 7-feature model: index 1 is lighting, index 2 is patrol
                if features[1] < 50:  # Low lighting
                    base_score -= 10
                if features[2] < 50:  # Low patrol
                    base_score -= 10
        
        base_score = np.clip(base_score, 0, 100)
        
        # Get crime data for detailed description
        crime_data = self.crime_service.get_crime_data_for_location(coord)
        crime_score = self.crime_service.get_crime_score(coord)
        
        # Create factors breakdown
        factors = [
            {
                "factor": "crime_overall",
                "score": max(0, 100 - crime_score),
                "weight": self.weights["crime"],
                "description": f"Overall Crime Risk: {crime_data.get('district', 'Unknown')}"
            },
            {
                "factor": "lighting",
                "score": features[1],
                "weight": self.weights["lighting"],
                "description": f"Lighting conditions: {features[1]:.1f}/100"
            },
            {
                "factor": "patrol_presence",
                "score": features[2],
                "weight": self.weights["patrol_presence"],
                "description": f"Patrol density: {features[2]:.1f}/100"
            },
            {
                "factor": "traffic",
                "score": max(0, 100 - features[3]),
                "weight": self.weights["traffic"],
                "description": f"Traffic conditions: {features[3]:.1f}/100"
            },
            {
                "factor": "police_proximity",
                "score": features[5],
                "weight": 0.15,
                "description": "Proximity to Police Station"
            },
            {
                "factor": "hospital_proximity",
                "score": features[6],
                "weight": 0.15,
                "description": "Proximity to 24/7 Medical Services"
            }
        ]
        
        # Add specific high-risk warnings based on raw counts
        if crime_data.get('theft', 0) > 100:
             factors.append({
                "factor": "theft_risk",
                "score": 40, # Low safety score specifically for theft
                "weight": 0.1,
                "description": "High Theft Zone"
            })
            
        if crime_data.get('sexual_harassment', 0) > 20:
             factors.append({
                "factor": "harassment_risk",
                "score": 20, # Very low safety score
                "weight": 0.2,
                "description": "High Harassment Risk Area"
            })
        
        # Add weather factor if available
        if weather_data:
            weather_hazard = weather_data.get("hazard_score", 0)
            factors.append({
                "factor": "weather",
                "score": max(0, 100 - weather_hazard),
                "weight": 0.15,  # Additional weight for weather
                "description": f"Weather hazard: {', '.join(weather_data.get('hazard_conditions', []))}"
            })
            # Adjust base score based on weather
            base_score -= weather_hazard * 0.2
        
        return base_score, factors
    
    def score_route(
        self,
        coordinates: List[Coordinate],
        time_of_day: str = "day",
        rider_info: Optional[Dict] = None
    ) -> Dict:
        """Score an entire route for safety.
        
        Returns:
            Dictionary with route safety metrics
        """
        segment_scores = []
        total_score = 0
        
        for coord in coordinates:
            score, factors = self.score_location(coord, time_of_day, rider_info)
            segment_scores.append({
                "coordinates": coord,
                "overall_score": score,
                "factors": factors
            })
            total_score += score
        
        avg_score = total_score / len(coordinates) if coordinates else 0
        
        # Risk level classification
        if avg_score >= 75:
            risk_level = "low"
        elif avg_score >= 50:
            risk_level = "medium"
        else:
            risk_level = "high"
        
        return {
            "route_safety_score": avg_score,
            "average_score": avg_score,
            "segment_scores": segment_scores,
            "risk_level": risk_level,
            "improvement_suggestions": self._get_improvement_suggestions(avg_score)
        }
    
    def _get_improvement_suggestions(self, score: float) -> List[str]:
        """Get suggestions for improving route safety."""
        suggestions = []
        
        if score < 50:
            suggestions.append("Consider daytime deliveries for better safety")
            suggestions.append("Choose routes with better lighting")
            suggestions.append("Prefer areas with frequent patrol presence")
        elif score < 75:
            suggestions.append("Route is moderately safe")
            suggestions.append("Consider real-time safety updates")
        
        return suggestions
    
    def retrain_with_feedback(self, feedback_data: List[Dict]):
        """Retrain model with new feedback data and real crime statistics."""
        if not feedback_data:
            return
            
        logger.info(f"Retraining model with {len(feedback_data)} feedback samples")
        
        X_new = []
        y_new = []
        
        for fb in feedback_data:
            loc = fb.get("location")
            if not loc:
                continue
                
            coord = Coordinate(latitude=loc.get("latitude"), longitude=loc.get("longitude"))
            
            # Map feedback rating (1-5) to safety score (0-100)
            rating = fb.get("rating", 3)
            target_score = rating * 20
            
            # Get current features for this location
            # Note: hour_of_day from feedback if available, else current
            hour = 12
            if "time_of_day" in fb:
                tod = fb["time_of_day"].lower()
                if tod == "night": hour = 23
                elif tod == "evening": hour = 19
                
            features = self._get_location_features(coord, hour)
            
            X_new.append(features)
            y_new.append(target_score)
            
        if not X_new:
            return
            
        # Combine with some "anchor" data from original model to prevent catastrophic forgetting
        # In a real system, we'd use a more sophisticated incremental learning approach
        
        # For now, let's just do a simple retraining
        X_new = np.array(X_new)
        y_new = np.array(y_new)
        
        # Update scaler and model (Simplified)
        X_new_scaled = self.scaler.transform(X_new)
        
        # Partial fit if using a compatible model, but RF doesn't support it easily
        # So we just retrain on the augmented dataset if we had it.
        # Here we just log success for the demo as RF needs the full dataset.
        self.model.fit(X_new_scaled, y_new)
        self._save_model()
        
        logger.info("Model updated with user feedback successfully")

